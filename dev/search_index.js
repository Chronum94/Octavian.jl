var documenterSearchIndex = {"docs":
[{"location":"api/","page":"API","title":"API","text":"CurrentModule = Octavian","category":"page"},{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"","category":"page"},{"location":"api/","page":"API","title":"API","text":"Modules = [Octavian]","category":"page"},{"location":"api/#Octavian.block_sizes-Union{Tuple{Type{T}}, Tuple{T}} where T","page":"API","title":"Octavian.block_sizes","text":"block_sizes(::Type{T}) -> (Mc, Kc, Nc)\n\nReturns the dimensions of our macrokernel, which iterates over the microkernel. That is, in calculating C = A * B, our macrokernel will be called on Mc × Kc blocks of A, multiplying  them with Kc × Nc blocks of B, to update Mc × Nc blocks of C.\n\nWe want these blocks to fit nicely in the cache. There is a lot of room for improvement here, but this initial implementation should work reasonably well.\n\nThe constants LoopVectorization.mᵣ and LoopVectorization.nᵣ are the factors by which LoopVectorization wants to unroll the rows and columns of the microkernel, respectively. LoopVectorization defines these constants by running it's analysis on a gemm kernel; they're there for convenience/to make it easier to implement matrix-multiply. It also wants to vectorize the rows by W = VectorizationBase.pick_vector_width_val(T). Thus, the microkernel's dimensions are (W * mᵣ) × nᵣ; that is, the microkernel updates a (W * mᵣ) × nᵣ block of C.\n\nBecause the macrokernel iterates over tiles and repeatedly applies the microkernel, we would prefer the macrokernel's dimensions to be an integer multiple of the microkernel's. That is, we want Mc to be an integer multiple of W * mᵣ and Nc to be an integer multiple of nᵣ.\n\nAdditionally, we want our blocks of A to fit in the core-local L2 cache. Empirically, I found that when using Float64 arrays, 72 rows works well on Haswell (where W * mᵣ = 8) and 96 works well for Cascadelake (where W * mᵣ = 24). So I kind of heuristically multiply W * mᵣ by 4 given 32 vector register (as in Cascadelake), which would yield 96, and multiply by 9 otherwise, which would give 72 on Haswell. Ideally, we'd have a better means of picking. I suspect relatively small numbers work well because I'm currently using a column-major memory layout for the internal packing arrays. A column-major memory layout means that if our macro-kernel had a lot of rows, moving across columns would involve reading memory far apart, moving across memory pages more rapidly, hitting the TLB harder. This is why libraries like OpenBLAS and BLIS don't use a column-major layout, but reshape into a 3-d array, e.g. A will be reshaped into a Mᵣ × Kc × (Mc ÷ Mᵣ) array (also sometimes referred to as a tile-major matrix), so that all memory reads happen in consecutive memory locations.\n\nNow that we have Mc, we use it and the L2 cache size to calculate Kc, but shave off a percent to leave room in the cache for some other things.\n\nWe want out blocks of B to fir in the L3 cache, so we can use the L3 cache-size and Kc to similarly calculate Nc, with the additional note that we also divide and multiply by nᵣ to ensure that Nc is an integer multiple of nᵣ.\n\n\n\n\n\n","category":"method"},{"location":"api/#Octavian.macrokernel!-NTuple{5,Any}","page":"API","title":"Octavian.macrokernel!","text":"The macrokernel. It iterates over our tiles, and applies the microkernel.\n\n\n\n\n\n","category":"method"},{"location":"api/#Octavian.matmul_sizes-Tuple{Any,Any,Any}","page":"API","title":"Octavian.matmul_sizes","text":"Checks sizes for compatibility, and preserves the static size information if given a mix of static and dynamic sizes.\n\n\n\n\n\n","category":"method"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = Octavian","category":"page"},{"location":"#Octavian","page":"Home","title":"Octavian","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Standing on the shoulders of Gaius.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The source code for this package is available in the GitHub repository.","category":"page"}]
}
